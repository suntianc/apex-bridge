/**
 * ApexBridge - èŠå¤©æœåŠ¡ï¼ˆABP-onlyï¼‰
 * å¤„ç†èŠå¤©è¯·æ±‚çš„å®Œæ•´ç”Ÿå‘½å‘¨æœŸ
 */

import { ProtocolEngine } from '../core/ProtocolEngine';
import { LLMManager as LLMClient } from '../core/LLMManager'; // å‘åå…¼å®¹åˆ«å
import { EventBus } from '../core/EventBus';
import {
  Message,
  ChatOptions
} from '../types';
import { ActiveRequest } from '../types/request-abort';
import { logger } from '../utils/logger';
import { generateRequestId } from '../utils/request-id';
import { TaskEvaluator } from '../core/TaskEvaluator';
import { IWebSocketManager } from '../api/websocket/WebSocketManager';
import { ConfigService } from './ConfigService';
import { AceService } from './AceService';

export class ChatService {

  // ğŸ†• æ´»åŠ¨è¯·æ±‚è¿½è¸ª
  private activeRequests: Map<string, ActiveRequest> = new Map();
  private cleanupTimer: NodeJS.Timeout | null = null;
  private webSocketManager: IWebSocketManager | null = null; // WebSocketManager å®ä¾‹ï¼ˆå¯é€‰ï¼‰

  private llmClient: LLMClient | null = null; // æ”¹ä¸ºå¯é€‰ï¼Œæ”¯æŒæ‡’åŠ è½½
  private aceService: AceService;

  constructor(
    private protocolEngine: ProtocolEngine,
    llmClient: LLMClient | null, // æ”¹ä¸ºå¯é€‰å‚æ•°
    private eventBus: EventBus
  ) {
    this.llmClient = llmClient; // å¯é€‰ï¼Œå¯ä»¥ä¸ºnullï¼ˆæ‡’åŠ è½½ï¼‰
    this.aceService = AceService.getInstance();

    // å°è¯•åˆå§‹åŒ– ACE (éé˜»å¡)
    this.aceService.initialize().catch(err => {
      logger.warn(`[ChatService] Failed to auto-init ACE: ${err.message}`);
    });

    logger.info('âœ… ChatService initialized (using ProtocolEngine unified variable engine)');

    // ğŸ†• å¯åŠ¨å®šæœŸæ¸…ç†ä»»åŠ¡ï¼ˆæ¯60ç§’ï¼‰
    this.startCleanupTimer();
  }

  /**
   * ğŸ†• è®¾ç½® WebSocketManagerï¼ˆç”¨äºä¸­æ–­é€šçŸ¥ï¼‰
   */
  setWebSocketManager(manager: IWebSocketManager): void {
    this.webSocketManager = manager;
    logger.debug('[ChatService] WebSocketManager attached');
  }

  /**
   * ğŸ†• æ³¨å†Œæ´»åŠ¨è¯·æ±‚
   */
  private registerRequest(requestId: string, abortController: AbortController, context?: any): void {
    const request: ActiveRequest = {
      requestId,
      abortController,
      startTime: Date.now(),
      context
    };

    this.activeRequests.set(requestId, request);
    logger.debug(`[ChatService] Registered request: ${requestId} (total: ${this.activeRequests.size})`);
  }

  /**
   * ğŸ†• ä¸­æ–­è¯·æ±‚
   */
  async interruptRequest(requestId: string): Promise<boolean> {
    const request = this.activeRequests.get(requestId);

    if (!request) {
      logger.warn(`[ChatService] Request not found for interrupt: ${requestId}`);
      return false;
    }

    logger.debug(`[ChatService] Interrupting request: ${requestId}`);

    // è§¦å‘ä¸­æ–­
    request.abortController.abort();

    // ğŸ†• æ¨é€ WebSocket é€šçŸ¥
    if (this.webSocketManager) {
      try {
        const abpLogChannel = this.webSocketManager.getChannel?.('ABPLog');

        if (abpLogChannel) {
          (abpLogChannel as any).pushLog?.({
            status: 'interrupted',
            content: `è¯·æ±‚å·²ä¸­æ–­: ${requestId}`,
            source: 'request_interrupt',
            metadata: {
              requestId: requestId,
              timestamp: new Date().toISOString(),
              duration: Date.now() - request.startTime
            }
          });

          logger.debug(`[ChatService] Pushed interrupt notification to ABPLog`);
        }
      } catch (wsError) {
        logger.warn(`[ChatService] WebSocket push failed (non-critical):`, wsError);
      }
    }

    // æ¸…ç†è¯·æ±‚
    this.cleanupRequest(requestId);

    return true;
  }

  /**
   * ğŸ†• æ¸…ç†è¯·æ±‚
   */
  private cleanupRequest(requestId: string): void {
    const request = this.activeRequests.get(requestId);

    if (request) {
      const duration = Date.now() - request.startTime;
      logger.debug(`[ChatService] Cleaning up request: ${requestId} (duration: ${duration}ms)`);
      this.activeRequests.delete(requestId);
    }
  }

  /**
   * ğŸ†• å¯åŠ¨å®šæœŸæ¸…ç†å®šæ—¶å™¨
   */
  private startCleanupTimer(): void {
    const intervalMs = parseInt(process.env.ACTIVE_REQUEST_CLEANUP_INTERVAL_MS || '60000');
    const timeoutMs = parseInt(process.env.REQUEST_TIMEOUT_MS || '300000'); // 5åˆ†é’Ÿ

    this.cleanupTimer = setInterval(() => {
      const now = Date.now();
      let cleanedCount = 0;

      for (const [requestId, request] of this.activeRequests.entries()) {
        const age = now - request.startTime;

        if (age > timeoutMs) {
          logger.warn(`[ChatService] Auto-cleaning timeout request: ${requestId} (age: ${age}ms)`);
          request.abortController.abort();
          this.activeRequests.delete(requestId);
          cleanedCount++;
        }
      }

      if (cleanedCount > 0) {
        logger.debug(`[ChatService] Cleaned ${cleanedCount} timeout request(s)`);
      }
    }, intervalMs);

    logger.debug(`[ChatService] Cleanup timer started (interval: ${intervalMs}ms, timeout: ${timeoutMs}ms)`);
  }

  /**
   * ğŸ†• åœæ­¢æ¸…ç†å®šæ—¶å™¨
   */
  stopCleanupTimer(): void {
    if (this.cleanupTimer) {
      clearInterval(this.cleanupTimer);
      this.cleanupTimer = null;
      logger.debug('[ChatService] Cleanup timer stopped');
    }
  }

  /**
   * ğŸ†• è·å–æ´»åŠ¨è¯·æ±‚æ•°é‡
   */
  getActiveRequestCount(): number {
    return this.activeRequests.size;
  }

  /**
   * ğŸ†• WebSocketé€‚é…æ–¹æ³• - åˆ›å»ºèŠå¤©å®Œæˆï¼ˆå…¼å®¹OpenAIæ ¼å¼ï¼‰
   */
  async createChatCompletion(params: {
    messages: Message[];
    model?: string;
    temperature?: number;
    max_tokens?: number;
    stream?: boolean;
    userId?: string;
    [key: string]: any;
  }): Promise<any> {
    const { messages, stream, ...options } = params;

    if (stream) {
      throw new Error('createChatCompletionä¸æ”¯æŒæµå¼å“åº”ï¼Œè¯·ä½¿ç”¨createStreamChatCompletion');
    }

    return this.processMessage(messages, options);
  }

  /**
   * ğŸ†• WebSocketé€‚é…æ–¹æ³• - åˆ›å»ºæµå¼èŠå¤©å®Œæˆ
   */
  async *createStreamChatCompletion(params: {
    messages: Message[];
    model?: string;
    temperature?: number;
    max_tokens?: number;
    stream?: boolean;
    userId?: string;
    [key: string]: any;
  }): AsyncIterableIterator<any> {
    const { messages, ...options } = params;

    // å°†streamMessageè½¬æ¢ä¸ºå…¼å®¹æ ¼å¼
    for await (const chunk of this.streamMessage(messages, options)) {
      // ğŸ›¡ï¸ å¤„ç† Meta åè®®å¤´ï¼Œè½¬æ¢ä¸ºäº‹ä»¶æ ¼å¼
      if (chunk.startsWith('__META__:')) {
        const metaJson = chunk.substring(9);
        try {
          const meta = JSON.parse(metaJson);

          // å°† requestId ä½œä¸º meta_event ä¼ é€’ï¼Œä¾› WebSocket å±‚ä½¿ç”¨
          if (meta.type === 'requestId') {
            yield {
              type: 'meta_event',
              payload: {
                requestId: meta.value
              }
            };
          } else if (meta.type === 'interrupted') {
            // ä¸­æ–­äº‹ä»¶ä¹Ÿè½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
            yield {
              type: 'meta_event',
              payload: {
                type: 'interrupted'
              }
            };
          }
          continue; // è·³è¿‡ META æ ‡è®°çš„åŸå§‹æ ¼å¼
        } catch (parseError) {
          logger.warn('[ChatService] Failed to parse meta chunk in WebSocket adapter:', metaJson);
          continue;
        }
      }

      // ç¡®ä¿ chunk ä¸æ˜¯ META æ ‡è®°ï¼ˆåŒé‡ä¿æŠ¤ï¼‰
      if (chunk.startsWith('__META__')) {
        logger.warn('[ChatService] Unhandled META chunk detected in WebSocket adapter, skipping:', chunk.substring(0, 50));
        continue;
      }

      // å‘é€æ­£å¸¸å†…å®¹
      yield {
        type: 'stream_chunk',
        payload: {
          choices: [{
            delta: {
              content: chunk
            }
          }]
        }
      };
    }

    // å‘é€å®Œæˆä¿¡å·
    yield {
      type: 'stream_done'
    };
  }

  /**
   * å¤„ç†èŠå¤©æ¶ˆæ¯
   */
  async processMessage(messages: Message[], options: ChatOptions = {}): Promise<any> {
    try {
      // ğŸ†• æ£€æŸ¥æ˜¯å¦å¯ç”¨è‡ªæˆ‘æ€è€ƒå¾ªç¯ï¼ˆReActæ¨¡å¼ï¼‰
      if (options.selfThinking?.enabled) {
        return this.processMessageWithSelfThinking(messages, options);
      }

      // åŸæœ‰çš„å•æ¬¡å¤„ç†é€»è¾‘
      return this.processSingleRound(messages, options);

    } catch (error: any) {
      logger.error('âŒ Error in ChatService.processMessage:', error);
      throw error;
    }
  }

  /**
   * å•è½®å¤„ç†é€»è¾‘ï¼ˆåŸæœ‰å®ç°ï¼‰
   */
  private async processSingleRound(messages: Message[], options: ChatOptions = {}): Promise<any> {
    logger.debug(`ğŸ“¨ Processing chat message, ${messages.length} messages`);

    let processedMessages = messages;

    // 1. å˜é‡æ›¿æ¢
    processedMessages = await this.resolveVariables(processedMessages);

    // 2. æ¶ˆæ¯é¢„å¤„ç†ï¼ˆç§»é™¤å¯¹æ’ä»¶ç³»ç»Ÿä¾èµ–ï¼Œç›´æ¥ä½¿ç”¨å˜é‡è§£æåçš„æ¶ˆæ¯ï¼‰
    const preprocessedMessages = processedMessages;

    // 3. è°ƒç”¨LLMï¼ˆæ‡’åŠ è½½LLMClientï¼‰
    const llmClient = await this.requireLLMClient();
    const llmResponse = await llmClient.chat(preprocessedMessages, options);
    const aiContent = llmResponse.choices[0]?.message?.content || '';

    logger.debug(`ğŸ¤– LLM Response (first 200 chars): ${aiContent.substring(0, 200)}`);

    return {
      content: aiContent,
      usage: llmResponse.usage
    };
  }

  /**
   * è‡ªæˆ‘æ€è€ƒå¾ªç¯ï¼ˆReActæ¨¡å¼ï¼‰
   *
   * å¾ªç¯æ‰§è¡Œï¼šæ€è€ƒ â†’ è¡ŒåŠ¨ â†’ è§‚å¯Ÿ â†’ è¯„ä¼° â†’ ç›´åˆ°ä»»åŠ¡å®Œæˆ
   */
  private async processMessageWithSelfThinking(
    messages: Message[],
    options: ChatOptions
  ): Promise<any> {
    const startTime = Date.now();
    const maxDuration = options.loopTimeout || 300000; // 5åˆ†é’Ÿ
    const maxIterations = options.selfThinking?.maxIterations || 5;
    // âœ… ä¿®å¤1ï¼šè‡ªæˆ‘æ€è€ƒå¾ªç¯é»˜è®¤å¯åŠ¨è¯„ä¼°
    const enableTaskEvaluation = options.selfThinking?.enableTaskEvaluation ?? true;
    const includeThoughtsInResponse = options.selfThinking?.includeThoughtsInResponse ?? true;

    // âœ… ä¿®å¤2ï¼šä»é…ç½®æ–‡ä»¶è¯»å–å¿«é€Ÿè¯„ä¼°/LLMè¯„ä¼°å¼€å…³ï¼Œè€Œä¸æ˜¯ä»å‚æ•°è¯»å–
    const configService = ConfigService.getInstance();
    const config = configService.readConfig();
    const useLLMEvaluation = config.selfThinking?.useLLMEvaluation ?? false;
    const evaluationModel = config.selfThinking?.evaluationModel;

    // è·å–ç”¨æˆ·åŸå§‹æŸ¥è¯¢ï¼ˆç¬¬ä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ï¼‰
    const userQuery = messages.find(msg => msg.role === 'user')?.content || '';

    let iteration = 0;
    // å…³é”®ä¿®å¤ï¼šä½¿ç”¨å¯å˜çš„æ¶ˆæ¯æ•°ç»„ï¼Œæ¯æ¬¡è¿­ä»£éƒ½ä¼šæ›´æ–°
    const currentMessages: Message[] = [...messages];
    let finalResult: any = null;
    const thinkingProcess: string[] = []; // è®°å½•æ€è€ƒè¿‡ç¨‹

    // âœ… ä¿®å¤å¹¶å‘ Bugï¼šä½¿ç”¨å±€éƒ¨å˜é‡è€Œä¸æ˜¯ç±»æˆå‘˜å˜é‡ï¼Œç¡®ä¿æ¯ä¸ªè¯·æ±‚ç‹¬äº«ä¸€ä¸ªå®ä¾‹
    const taskEvaluator = new TaskEvaluator({
      maxIterations,
      completionPrompt: options.selfThinking?.completionPrompt,
      model: evaluationModel // âœ… ä»é…ç½®æ–‡ä»¶è¯»å–è¯„ä¼°æ¨¡å‹
    });

    logger.info(`ğŸ§  Starting Self-Thinking Loop (max: ${maxIterations} iterations)`);

    while (iteration < maxIterations) {
      iteration++;

      logger.info(`\nğŸ”„ [Self-Thinking Loop Iteration ${iteration}/${maxIterations}]`);

      // æ£€æŸ¥è¶…æ—¶
      if (Date.now() - startTime > maxDuration) {
        logger.warn(`âš ï¸ Self-thinking loop timeout (${maxDuration}ms) reached`);
        thinkingProcess.push(`[ç³»ç»Ÿè­¦å‘Š] è¾¾åˆ°æœ€å¤§è¶…æ—¶æ—¶é—´ï¼Œåœæ­¢å¾ªç¯`);
        break;
      }

      // æ­¥éª¤ 1: è°ƒç”¨ LLM
      logger.debug('ğŸ¤– Calling LLM...');
      const llmClient = await this.requireLLMClient();
      const llmResponse = await llmClient.chat(currentMessages, options);
      const aiContent = llmResponse.choices[0]?.message?.content || '';

      logger.debug(`ğŸ“ LLM Response: ${aiContent.substring(0, 200)}...`);

      // è®°å½•æ€è€ƒè¿‡ç¨‹
      thinkingProcess.push(`\n[æ€è€ƒæ­¥éª¤ ${iteration}]`);
      thinkingProcess.push(`AIåˆ†æ: ${aiContent}`);

      // å…³é”®ä¿®å¤ï¼šæ›´æ–°ä¸Šä¸‹æ–‡ï¼Œè®©æ¨¡å‹çŸ¥é“å®ƒä¹‹å‰çš„æ€è€ƒ
      currentMessages.push({
        role: 'assistant',
        content: aiContent
      });

      // æ­¥éª¤ 2: ä½¿ç”¨ TaskEvaluator è¯„ä¼°ä»»åŠ¡æ˜¯å¦å®Œæˆ
      let shouldContinue = false;
      if (enableTaskEvaluation && taskEvaluator) {
        // âœ… ä»é…ç½®æ–‡ä»¶è¯»å–è¯„ä¼°æ–¹å¼ï¼Œè€Œä¸æ˜¯ä»å‚æ•°è¯»å–
        if (useLLMEvaluation) {
          // ğŸ†• ä½¿ç”¨çœŸå®çš„ LLM è¯„ä¼°ï¼ˆæ›´å‡†ç¡®ä½†æˆæœ¬æ›´é«˜ï¼‰
          logger.debug('[TaskEvaluator] Using LLM-based evaluation');
          try {
            const evaluation = await taskEvaluator.evaluate(
              llmClient,
              currentMessages,
              userQuery,
              iteration
            );
            shouldContinue = !evaluation.isComplete;

            logger.debug(
              `[TaskEvaluator] LLM Evaluation result: ${evaluation.isComplete ? 'Complete' : 'Needs more work'}` +
              (evaluation.reasoning ? ` (Reasoning: ${evaluation.reasoning.substring(0, 100)}...)` : '')
            );

            // å¦‚æœæä¾›äº†å»ºè®®çš„ä¸‹ä¸€æ­¥è¡ŒåŠ¨ï¼Œå¯ä»¥è®°å½•åˆ°æ€è€ƒè¿‡ç¨‹ä¸­
            if (evaluation.suggestedNextAction) {
              thinkingProcess.push(`[è¯„ä¼°å»ºè®®] ${evaluation.suggestedNextAction}`);
            }

            // å¦‚æœè¯„ä¼°æä¾›äº†æ¨ç†è¿‡ç¨‹ï¼Œä¹Ÿè®°å½•åˆ°æ€è€ƒè¿‡ç¨‹ä¸­
            if (evaluation.reasoning) {
              thinkingProcess.push(`[è¯„ä¼°æ¨ç†] ${evaluation.reasoning}`);
            }
          } catch (error: any) {
            // å¦‚æœ LLM è¯„ä¼°å¤±è´¥ï¼Œé™çº§åˆ°å¿«é€Ÿè¯„ä¼°
            logger.warn(`[TaskEvaluator] LLM evaluation failed, falling back to quick evaluation: ${error.message || error}`);
            const evaluation = taskEvaluator.quickEvaluate(currentMessages);
            shouldContinue = !evaluation.isLikelyComplete;
            logger.debug(`[TaskEvaluator] Quick Evaluation (fallback) result: ${evaluation.isLikelyComplete ? 'Complete' : 'Needs more work'}`);
          }
        } else {
          // ä½¿ç”¨å¿«é€Ÿè¯„ä¼°ï¼ˆè½»é‡çº§ï¼ŒåŸºäºå…³é”®è¯åŒ¹é…ï¼‰
          logger.debug('[TaskEvaluator] Using quick evaluation (keyword-based)');
          const evaluation = taskEvaluator.quickEvaluate(currentMessages);
          shouldContinue = !evaluation.isLikelyComplete;

          logger.debug(`[TaskEvaluator] Quick Evaluation result: ${evaluation.isLikelyComplete ? 'Complete' : 'Needs more work'}`);
        }
      } else {
        // å¦‚æœæ²¡æœ‰å¯ç”¨è¯„ä¼°ï¼Œé»˜è®¤åœ¨è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°æ—¶ç»“æŸ
        shouldContinue = iteration < maxIterations;
      }

      // å¦‚æœä»»åŠ¡å®Œæˆæˆ–è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œç»“æŸå¾ªç¯
      if (!shouldContinue || iteration >= maxIterations) {
        finalResult = {
          content: aiContent,
          iterations: iteration,
          thinkingProcess: includeThoughtsInResponse ? thinkingProcess.join('\n') : undefined,
          usage: llmResponse.usage
        };

        // ğŸš€ ACE Integration: Capture Trajectory
        // Only evolve if we have a valid result and ACE is active
        if (this.aceService.getAgent()) {
          const outcome = shouldContinue ? 'FAILURE' : 'SUCCESS'; // If loop broke early, it's success

          // Generate a unique task ID if not present (using request ID context if available)
          // For now we use a random UUID if requestId is not easily accessible here, 
          // but ideally we should pass requestId through options
          const taskId = options.requestId || `task_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;

          const trajectory = {
            task_id: taskId,
            user_input: userQuery,
            steps: thinkingProcess.map(t => ({
              thought: t,
              action: 'think',
              output: ''
            })),
            final_result: aiContent,
            outcome: outcome as 'SUCCESS' | 'FAILURE',
            environment_feedback: 'TaskEvaluator: ' + (shouldContinue ? 'Max iterations reached' : 'Task completed'),
            used_rule_ids: [], // We don't track rule usage in ApexBridge yet
            timestamp: Date.now(),
            duration_ms: Date.now() - startTime,
            evolution_status: 'PENDING' as const
          };

          this.aceService.evolve(trajectory).catch(err => {
            logger.error(`[ChatService] ACE Evolution failed: ${err.message}`);
          });
        }

        break;
      }

      // æ­¥éª¤ 3: å¦‚æœä»»åŠ¡æœªå®Œæˆï¼Œæ·»åŠ æç¤ºæ¶ˆæ¯æ¨åŠ¨ç»§ç»­æ€è€ƒ
      currentMessages.push({
        role: 'user',
        content: 'è¯·ç»§ç»­ä¸‹ä¸€æ­¥åˆ†æï¼Œæˆ–ç»™å‡ºæœ€ç»ˆç»“è®ºã€‚å¦‚æœä»»åŠ¡å·²å®Œæˆï¼Œè¯·æ˜ç¡®è¯´æ˜ã€‚'
      });

      // æ¸…ç†ï¼šä¿æŒä¸Šä¸‹æ–‡å¤§å°å¯æ§
      if (currentMessages.length > 50) {
        logger.warn(`âš ï¸ æ¶ˆæ¯å†å²è¿‡é•¿(${currentMessages.length}æ¡)ï¼Œå¯èƒ½å½±å“æ€§èƒ½`);
        // ä¿ç•™å‰å‡ æ¡ç³»ç»Ÿæ¶ˆæ¯å’Œæœ€å20æ¡æ¶ˆæ¯
        const systemMessages = currentMessages.filter(msg => msg.role === 'system');
        const recentMessages = currentMessages.slice(-20);
        currentMessages.length = 0;
        currentMessages.push(...systemMessages, ...recentMessages);
      }
    }

    // å¦‚æœå¾ªç¯ç»“æŸä½†æ²¡æœ‰ç”Ÿæˆç»“æœï¼Œè¿”å›æœ€åä¸€æ¡ AI å›å¤
    if (!finalResult) {
      logger.warn(`âš ï¸ Self-thinking loop ended without clear result`);

      const lastAssistantMessage = [...currentMessages].reverse().find(msg => msg.role === 'assistant');
      const aiContent = lastAssistantMessage?.content || 'æ€è€ƒå¾ªç¯ç»“æŸï¼Œä½†æœªç”Ÿæˆæ˜ç¡®ç»“æœã€‚';

      finalResult = {
        content: aiContent,
        iterations: iteration,
        thinkingProcess: includeThoughtsInResponse ? thinkingProcess.join('\n') : undefined
      };
    }

    logger.info(`âœ… Self-thinking loop completed in ${iteration} iterations`);

    return finalResult;
  }

  /**
   * æµå¼å¤„ç†æ¶ˆæ¯
   */
  async *streamMessage(
    messages: Message[],
    options: ChatOptions = {}
  ): AsyncIterableIterator<string> {
    // ğŸ†• 0. ç”Ÿæˆè¯·æ±‚IDå’Œä¸­æ–­æ§åˆ¶å™¨
    const requestId = generateRequestId();
    const abortController = new AbortController();

    // ğŸ†• 0.1 æ³¨å†Œè¯·æ±‚
    this.registerRequest(requestId, abortController, {
      model: options.model,
      messageCount: messages.length
    });

    // ğŸ†• 0.2 å‘é€è¯·æ±‚IDç»™å®¢æˆ·ç«¯ï¼ˆå…ƒæ•°æ®æ ‡è®°ï¼‰
    yield `__META__:${JSON.stringify({ type: 'requestId', value: requestId })}`;

    try {
      let processedMessages = messages;

      // 1. å˜é‡æ›¿æ¢
      processedMessages = await this.resolveVariables(processedMessages);

      // 2. æ¶ˆæ¯é¢„å¤„ç†
      const preprocessedMessages = processedMessages;

      // 3. æµå¼è°ƒç”¨LLMï¼ˆä¼ é€’ä¸­æ–­ä¿¡å·ï¼‰
      // ä¿®å¤ï¼šä½¿ç”¨ requireLLMClient é¿å…ä»£ç é‡å¤
      const llmClient = await this.requireLLMClient();

      try {
        for await (const chunk of llmClient.streamChat(preprocessedMessages, options, abortController.signal)) {
          // ğŸ†• æ£€æŸ¥ä¸­æ–­
          if (abortController.signal.aborted) {
            logger.debug(`[ChatService] Request interrupted during LLM streaming: ${requestId}`);
            // ä¿®å¤ï¼šå‘é€ä¸­æ–­å…ƒæ•°æ®ï¼Œä½†ä¸å‘é€é”™è¯¯æ–‡æœ¬ç»™ç”¨æˆ·
            yield `__META__:${JSON.stringify({ type: 'interrupted' })}`;
            return;
          }

          yield chunk;
        }
      } catch (error: any) {
        // ğŸ†• æ•è·ä¸­æ–­é”™è¯¯
        if (error.name === 'AbortError' || error.code === 'ERR_CANCELED') {
          logger.debug(`[ChatService] Request aborted: ${requestId}`);
          // ä¿®å¤ï¼šå‘é€ä¸­æ–­å…ƒæ•°æ®ï¼Œä½†ä¸å‘é€é”™è¯¯æ–‡æœ¬ç»™ç”¨æˆ·
          yield `__META__:${JSON.stringify({ type: 'interrupted' })}`;
          return;
        }

        // ä¿®å¤ï¼šå¯¹äºéä¸­æ–­é”™è¯¯ï¼ŒæŠ›å‡ºå¼‚å¸¸è€Œä¸æ˜¯ yield é”™è¯¯æ–‡æœ¬
        logger.error(`âŒ LLM request failed: ${error.message}`);
        throw error; // è®©ä¸Šå±‚å¤„ç†é”™è¯¯ï¼Œè€Œä¸æ˜¯åœ¨æµä¸­å‘é€é”™è¯¯æ–‡æœ¬
      }

    } catch (error: any) {
      // ğŸ†• æ£€æŸ¥æ˜¯å¦ä¸ºä¸­æ–­é”™è¯¯
      if (error.name === 'AbortError' || error.code === 'ERR_CANCELED') {
        logger.debug(`[ChatService] Request aborted in catch block: ${requestId}`);
        // ä¿®å¤ï¼šå‘é€ä¸­æ–­å…ƒæ•°æ®ï¼Œä½†ä¸å‘é€é”™è¯¯æ–‡æœ¬ç»™ç”¨æˆ·
        yield `__META__:${JSON.stringify({ type: 'interrupted' })}`;
        return;
      }

      logger.error('âŒ Error in ChatService.streamMessage:', error);
      // ä¿®å¤ï¼šå¯¹äºéä¸­æ–­é”™è¯¯ï¼ŒæŠ›å‡ºå¼‚å¸¸è€Œä¸æ˜¯ yield é”™è¯¯æ–‡æœ¬
      throw error;
    } finally {
      // ğŸ†• æ— è®ºæˆåŠŸæˆ–å¤±è´¥ï¼Œéƒ½æ¸…ç†è¯·æ±‚
      this.cleanupRequest(requestId);
    }
  }

  private async requireLLMClient(): Promise<LLMClient> {
    let llmClient = this.llmClient;
    if (!llmClient) {
      // LLMManager æ”¯æŒæ‡’åŠ è½½ï¼Œä» SQLite åŠ è½½é…ç½®
      const { LLMManager } = await import('../core/LLMManager');
      llmClient = new LLMManager() as LLMClient;
      if (!llmClient) {
        throw new Error('LLMClient not available. Please configure LLM providers in admin panel.');
      }
      this.llmClient = llmClient;
    }
    return llmClient;
  }

  /**
   * è§£ææ¶ˆæ¯ä¸­çš„å˜é‡
   * 
   * ä½¿ç”¨SDK VariableEngineç»Ÿä¸€å¤„ç†æ‰€æœ‰å˜é‡å ä½ç¬¦ï¼š
   * - {{Date}}, {{Time}}, {{Today}} - æ—¶é—´å˜é‡ï¼ˆTimeProviderï¼‰
   * - è‡ªå®šä¹‰å ä½ç¬¦ï¼ˆPlaceholderProviderï¼‰
   * 
   * å¦‚æœå˜é‡è§£æå¤±è´¥ï¼Œä¼šé™çº§ä½¿ç”¨åŸå§‹æ–‡æœ¬ï¼Œç¡®ä¿è¯·æ±‚ä¸ä¼šå› å˜é‡è§£æé”™è¯¯è€Œå¤±è´¥ã€‚
   * 
   * @param messages - æ¶ˆæ¯æ•°ç»„
   * @returns è§£æåçš„æ¶ˆæ¯æ•°ç»„
   */
  private async resolveVariables(messages: Message[]): Promise<Message[]> {
    logger.debug(`[SDK] Resolving variables in ${messages.length} messages`);

    return Promise.all(
      messages.map(async (msg) => {
        if (!msg.content || typeof msg.content !== 'string') {
          return msg;
        }

        const originalContent = msg.content;
        const originalLength = originalContent.length;

        try {
          // ğŸ¯ ä½¿ç”¨ProtocolEngineçš„VariableEngineï¼Œä¼ é€’å®Œæ•´çš„VariableContext
          // åŒ…æ‹¬roleã€modelç­‰ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œæ”¯æŒroleè¿‡æ»¤æœºåˆ¶
          const resolvedContent = await this.protocolEngine.variableEngine.resolveAll(
            originalContent,
            {
              role: msg.role || 'system', // ä¼ é€’æ¶ˆæ¯è§’è‰²
              currentMessage: originalContent
            }
          );

          // è°ƒè¯•æ—¥å¿—ï¼šæ˜¾ç¤ºè§£æå‰åçš„é•¿åº¦å˜åŒ–
          if (originalLength !== resolvedContent.length) {
            logger.debug(
              `[SDK] Variable resolved (${msg.role}): ${originalLength} â†’ ${resolvedContent.length} chars (+${resolvedContent.length - originalLength})`
            );
          }

          return { ...msg, content: resolvedContent };
        } catch (error: any) {
          // ğŸ›¡ï¸ å˜é‡è§£æå¤±è´¥æ—¶é™çº§ä½¿ç”¨åŸå§‹æ–‡æœ¬ï¼Œç¡®ä¿è¯·æ±‚ä¸ä¼šå› å˜é‡è§£æé”™è¯¯è€Œå¤±è´¥
          logger.warn(
            `[SDK] Variable resolution failed for message (${msg.role}), using original content: ${error.message || error}`
          );

          // é™çº§ï¼šè¿”å›åŸå§‹æ¶ˆæ¯å†…å®¹
          return { ...msg, content: originalContent };
        }
      })
    );
  }

}

