/**
 * ApexBridge - èŠå¤©æœåŠ¡ï¼ˆABP-onlyï¼‰
 * å¤„ç†èŠå¤©è¯·æ±‚çš„å®Œæ•´ç”Ÿå‘½å‘¨æœŸ
 */

import { ProtocolEngine } from '../core/ProtocolEngine';
import { LLMManager as LLMClient } from '../core/LLMManager'; // å‘åå…¼å®¹åˆ«å
import { EventBus } from '../core/EventBus';
import {
  Message,
  ChatOptions
} from '../types';
import { ActiveRequest } from '../types/request-abort';
import { logger } from '../utils/logger';
import { generateRequestId } from '../utils/request-id';
import { TaskEvaluator } from '../core/TaskEvaluator';

export class ChatService {

  // ğŸ†• æ´»åŠ¨è¯·æ±‚è¿½è¸ª
  private activeRequests: Map<string, ActiveRequest> = new Map();
  private cleanupTimer: NodeJS.Timeout | null = null;
  private webSocketManager: any = null; // WebSocketManager å®ä¾‹ï¼ˆå¯é€‰ï¼‰
  // ğŸ†• è‡ªæˆ‘æ€è€ƒå¾ªç¯ï¼ˆReActæ¨¡å¼ï¼‰
  private taskEvaluator?: TaskEvaluator;

  private llmClient: LLMClient | null = null; // æ”¹ä¸ºå¯é€‰ï¼Œæ”¯æŒæ‡’åŠ è½½
  
  constructor(
    private protocolEngine: ProtocolEngine,
    llmClient: LLMClient | null, // æ”¹ä¸ºå¯é€‰å‚æ•°
    private eventBus: EventBus
  ) {
    this.llmClient = llmClient; // å¯é€‰ï¼Œå¯ä»¥ä¸ºnullï¼ˆæ‡’åŠ è½½ï¼‰
    logger.info('âœ… ChatService initialized (using ProtocolEngine unified variable engine)');
    
    // ğŸ†• å¯åŠ¨å®šæœŸæ¸…ç†ä»»åŠ¡ï¼ˆæ¯60ç§’ï¼‰
    this.startCleanupTimer();
  }
  
  /**
   * ğŸ†• è®¾ç½® WebSocketManagerï¼ˆç”¨äºä¸­æ–­é€šçŸ¥ï¼‰
   */
  setWebSocketManager(manager: any): void {
    this.webSocketManager = manager;
    logger.debug('[ChatService] WebSocketManager attached');
  }
  
  /**
   * ğŸ†• æ³¨å†Œæ´»åŠ¨è¯·æ±‚
   */
  private registerRequest(requestId: string, abortController: AbortController, context?: any): void {
    const request: ActiveRequest = {
      requestId,
      abortController,
      startTime: Date.now(),
      context
    };
    
    this.activeRequests.set(requestId, request);
    logger.debug(`[ChatService] Registered request: ${requestId} (total: ${this.activeRequests.size})`);
  }
  
  /**
   * ğŸ†• ä¸­æ–­è¯·æ±‚
   */
  async interruptRequest(requestId: string): Promise<boolean> {
    const request = this.activeRequests.get(requestId);
    
    if (!request) {
      logger.warn(`[ChatService] Request not found for interrupt: ${requestId}`);
      return false;
    }
    
    logger.debug(`[ChatService] Interrupting request: ${requestId}`);
    
    // è§¦å‘ä¸­æ–­
    request.abortController.abort();
    
    // ğŸ†• æ¨é€ WebSocket é€šçŸ¥
    if (this.webSocketManager) {
      try {
        const abpLogChannel = this.webSocketManager.getChannel?.('ABPLog');
        
        if (abpLogChannel) {
          (abpLogChannel as any).pushLog?.({
            status: 'interrupted',
            content: `è¯·æ±‚å·²ä¸­æ–­: ${requestId}`,
            source: 'request_interrupt',
            metadata: {
              requestId: requestId,
              timestamp: new Date().toISOString(),
              duration: Date.now() - request.startTime
            }
          });
          
          logger.debug(`[ChatService] Pushed interrupt notification to ABPLog`);
        }
      } catch (wsError) {
        logger.warn(`[ChatService] WebSocket push failed (non-critical):`, wsError);
      }
    }
    
    // æ¸…ç†è¯·æ±‚
    this.cleanupRequest(requestId);
    
    return true;
  }
  
  /**
   * ğŸ†• æ¸…ç†è¯·æ±‚
   */
  private cleanupRequest(requestId: string): void {
    const request = this.activeRequests.get(requestId);
    
    if (request) {
      const duration = Date.now() - request.startTime;
      logger.debug(`[ChatService] Cleaning up request: ${requestId} (duration: ${duration}ms)`);
      this.activeRequests.delete(requestId);
    }
  }
  
  /**
   * ğŸ†• å¯åŠ¨å®šæœŸæ¸…ç†å®šæ—¶å™¨
   */
  private startCleanupTimer(): void {
    const intervalMs = parseInt(process.env.ACTIVE_REQUEST_CLEANUP_INTERVAL_MS || '60000');
    const timeoutMs = parseInt(process.env.REQUEST_TIMEOUT_MS || '300000'); // 5åˆ†é’Ÿ
    
    this.cleanupTimer = setInterval(() => {
      const now = Date.now();
      let cleanedCount = 0;
      
      for (const [requestId, request] of this.activeRequests.entries()) {
        const age = now - request.startTime;
        
        if (age > timeoutMs) {
          logger.warn(`[ChatService] Auto-cleaning timeout request: ${requestId} (age: ${age}ms)`);
          request.abortController.abort();
          this.activeRequests.delete(requestId);
          cleanedCount++;
        }
      }
      
      if (cleanedCount > 0) {
        logger.debug(`[ChatService] Cleaned ${cleanedCount} timeout request(s)`);
      }
    }, intervalMs);
    
    logger.debug(`[ChatService] Cleanup timer started (interval: ${intervalMs}ms, timeout: ${timeoutMs}ms)`);
  }
  
  /**
   * ğŸ†• åœæ­¢æ¸…ç†å®šæ—¶å™¨
   */
  stopCleanupTimer(): void {
    if (this.cleanupTimer) {
      clearInterval(this.cleanupTimer);
      this.cleanupTimer = null;
      logger.debug('[ChatService] Cleanup timer stopped');
    }
  }
  
  /**
   * ğŸ†• è·å–æ´»åŠ¨è¯·æ±‚æ•°é‡
   */
  getActiveRequestCount(): number {
    return this.activeRequests.size;
  }
  
  /**
   * ğŸ†• WebSocketé€‚é…æ–¹æ³• - åˆ›å»ºèŠå¤©å®Œæˆï¼ˆå…¼å®¹OpenAIæ ¼å¼ï¼‰
   */
  async createChatCompletion(params: {
    messages: Message[];
    model?: string;
    temperature?: number;
    max_tokens?: number;
    stream?: boolean;
    userId?: string;
    [key: string]: any;
  }): Promise<any> {
    const { messages, stream, ...options } = params;

    if (stream) {
      throw new Error('createChatCompletionä¸æ”¯æŒæµå¼å“åº”ï¼Œè¯·ä½¿ç”¨createStreamChatCompletion');
    }

    return this.processMessage(messages, options);
  }

  /**
   * ğŸ†• WebSocketé€‚é…æ–¹æ³• - åˆ›å»ºæµå¼èŠå¤©å®Œæˆ
   */
  async *createStreamChatCompletion(params: {
    messages: Message[];
    model?: string;
    temperature?: number;
    max_tokens?: number;
    stream?: boolean;
    userId?: string;
    [key: string]: any;
  }): AsyncIterableIterator<any> {
    const { messages, ...options } = params;

    // å°†streamMessageè½¬æ¢ä¸ºå…¼å®¹æ ¼å¼
    for await (const chunk of this.streamMessage(messages, options)) {
      yield {
        type: 'stream_chunk',
        payload: {
          choices: [{
            delta: {
              content: chunk
            }
          }]
        }
      };
    }

    // å‘é€å®Œæˆä¿¡å·
    yield {
      type: 'stream_done'
    };
  }

  /**
   * å¤„ç†èŠå¤©æ¶ˆæ¯
   */
  async processMessage(messages: Message[], options: ChatOptions = {}): Promise<any> {
    try {
      // ğŸ†• æ£€æŸ¥æ˜¯å¦å¯ç”¨è‡ªæˆ‘æ€è€ƒå¾ªç¯ï¼ˆReActæ¨¡å¼ï¼‰
      if (options.selfThinking?.enabled) {
        return this.processMessageWithSelfThinking(messages, options);
      }

      // åŸæœ‰çš„å•æ¬¡å¤„ç†é€»è¾‘
      return this.processSingleRound(messages, options);

    } catch (error: any) {
      logger.error('âŒ Error in ChatService.processMessage:', error);
      throw error;
    }
  }

  /**
   * å•è½®å¤„ç†é€»è¾‘ï¼ˆåŸæœ‰å®ç°ï¼‰
   */
  private async processSingleRound(messages: Message[], options: ChatOptions = {}): Promise<any> {
    logger.debug(`ğŸ“¨ Processing chat message, ${messages.length} messages`);

    let processedMessages = messages;

    // 1. å˜é‡æ›¿æ¢
    processedMessages = await this.resolveVariables(processedMessages);

    // 2. æ¶ˆæ¯é¢„å¤„ç†ï¼ˆç§»é™¤å¯¹æ’ä»¶ç³»ç»Ÿä¾èµ–ï¼Œç›´æ¥ä½¿ç”¨å˜é‡è§£æåçš„æ¶ˆæ¯ï¼‰
    const preprocessedMessages = processedMessages;

    // 3. è°ƒç”¨LLMï¼ˆæ‡’åŠ è½½LLMClientï¼‰
    const llmClient = await this.requireLLMClient();
    const llmResponse = await llmClient.chat(preprocessedMessages, options);
    const aiContent = llmResponse.choices[0]?.message?.content || '';

    logger.debug(`ğŸ¤– LLM Response (first 200 chars): ${aiContent.substring(0, 200)}`);

    return {
      content: aiContent
    };
  }

  /**
   * è‡ªæˆ‘æ€è€ƒå¾ªç¯ï¼ˆReActæ¨¡å¼ï¼‰
   *
   * å¾ªç¯æ‰§è¡Œï¼šæ€è€ƒ â†’ è¡ŒåŠ¨ â†’ è§‚å¯Ÿ â†’ è¯„ä¼° â†’ ç›´åˆ°ä»»åŠ¡å®Œæˆ
   */
  private async processMessageWithSelfThinking(
    messages: Message[],
    options: ChatOptions
  ): Promise<any> {
    const startTime = Date.now();
    const maxDuration = options.loopTimeout || 300000; // 5åˆ†é’Ÿ
    const maxIterations = options.selfThinking?.maxIterations || 5;
    const enableTaskEvaluation = options.selfThinking?.enableTaskEvaluation ?? true;
    const includeThoughtsInResponse = options.selfThinking?.includeThoughtsInResponse ?? true;

    // è·å–ç”¨æˆ·åŸå§‹æŸ¥è¯¢ï¼ˆç¬¬ä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ï¼‰
    const userQuery = messages.find(msg => msg.role === 'user')?.content || '';

    let iteration = 0;
    let currentMessages = [...messages];
    let finalResult: any = null;
    const thinkingProcess: string[] = []; // è®°å½•æ€è€ƒè¿‡ç¨‹

    // åˆå§‹åŒ– TaskEvaluator
    this.taskEvaluator = new TaskEvaluator({
      maxIterations,
      completionPrompt: options.selfThinking?.completionPrompt
    });

    logger.info(`ğŸ§  Starting Self-Thinking Loop (max: ${maxIterations} iterations)`);

    while (iteration < maxIterations) {
      iteration++;

      logger.info(`\nğŸ”„ [Self-Thinking Loop Iteration ${iteration}/${maxIterations}]`);

      // æ£€æŸ¥è¶…æ—¶
      if (Date.now() - startTime > maxDuration) {
        logger.warn(`âš ï¸ Self-thinking loop timeout (${maxDuration}ms) reached`);
        thinkingProcess.push(`[ç³»ç»Ÿè­¦å‘Š] è¾¾åˆ°æœ€å¤§è¶…æ—¶æ—¶é—´ï¼Œåœæ­¢å¾ªç¯`);
        break;
      }

      // æ­¥éª¤ 1: è°ƒç”¨ LLM
      logger.debug('ğŸ¤– Calling LLM...');
      const llmClient = await this.requireLLMClient();
      const llmResponse = await llmClient.chat(currentMessages, options);
      const aiContent = llmResponse.choices[0]?.message?.content || '';

      logger.debug(`ğŸ“ LLM Response: ${aiContent.substring(0, 200)}...`);

      // è®°å½•æ€è€ƒè¿‡ç¨‹
      thinkingProcess.push(`\n[æ€è€ƒæ­¥éª¤ ${iteration}]`);
      thinkingProcess.push(`AIåˆ†æ: ${aiContent}`);

      logger.debug('â„¹ï¸ Task marked as complete');
      finalResult = {
        content: aiContent,
        iterations: iteration,
        thinkingProcess: includeThoughtsInResponse ? thinkingProcess.join('\n') : undefined
      };
      break;

      // æ¸…ç†ï¼šä¿æŒä¸Šä¸‹æ–‡å¤§å°å¯æ§
      if (currentMessages.length > 50) {
        logger.warn(`âš ï¸ æ¶ˆæ¯å†å²è¿‡é•¿(${currentMessages.length}æ¡)ï¼Œå¯èƒ½å½±å“æ€§èƒ½`);
      }
    }

    if (!finalResult) {
      // å¦‚æœå¾ªç¯ç»“æŸä½†æ²¡æœ‰ç”Ÿæˆç»“æœï¼Œè¿”å›æœ€åä¸€æ¡æ¶ˆæ¯
      logger.warn(`âš ï¸ Self-thinking loop ended without clear result`);

      const llmClient = await this.requireLLMClient();
      const llmResponse = await llmClient.chat(currentMessages, options);
      const aiContent = llmResponse.choices[0]?.message?.content || '';

      finalResult = {
        content: aiContent,
        iterations: iteration,
        thinkingProcess: includeThoughtsInResponse ? thinkingProcess.join('\n') : undefined
      };
    }

    logger.info(`âœ… Self-thinking loop completed in ${iteration} iterations`);

    return finalResult;
  }
  
  /**
   * æµå¼å¤„ç†æ¶ˆæ¯
   */
  async *streamMessage(
    messages: Message[],
    options: ChatOptions = {}
  ): AsyncIterableIterator<string> {
    // ğŸ†• 0. ç”Ÿæˆè¯·æ±‚IDå’Œä¸­æ–­æ§åˆ¶å™¨
    const requestId = generateRequestId();
    const abortController = new AbortController();
    
    // ğŸ†• 0.1 æ³¨å†Œè¯·æ±‚
    this.registerRequest(requestId, abortController, {
      model: options.model,
      messageCount: messages.length
    });
    
    // ğŸ†• 0.2 å‘é€è¯·æ±‚IDç»™å®¢æˆ·ç«¯ï¼ˆå…ƒæ•°æ®æ ‡è®°ï¼‰
    yield `__META__:${JSON.stringify({type:'requestId',value:requestId})}`;
    
    try {
      let processedMessages = messages;
      
      // 1. å˜é‡æ›¿æ¢
      processedMessages = await this.resolveVariables(processedMessages);
      
      // 2. æ¶ˆæ¯é¢„å¤„ç†
      const preprocessedMessages = processedMessages;
      
      // 3. æµå¼è°ƒç”¨LLMï¼ˆä¼ é€’ä¸­æ–­ä¿¡å·ï¼‰
      let llmClient = this.llmClient;
      if (!llmClient) {
        const { LLMManager } = await import('../core/LLMManager');
        llmClient = new LLMManager() as LLMClient;
        if (!llmClient) {
          throw new Error('LLMClient not available. Please configure LLM providers in admin panel.');
        }
        this.llmClient = llmClient;
      }
      
      try {
        for await (const chunk of llmClient.streamChat(preprocessedMessages, options, abortController.signal)) {
          // ğŸ†• æ£€æŸ¥ä¸­æ–­
          if (abortController.signal.aborted) {
            logger.debug(`[ChatService] Request interrupted during LLM streaming: ${requestId}`);
            yield `\n\n[ç”¨æˆ·å·²ä¸­æ–­è¯·æ±‚]`;
            yield `__META__:${JSON.stringify({type:'interrupted'})}`;
            return;
          }
          
          yield chunk;
        }
      } catch (error: any) {
        // ğŸ†• æ•è·ä¸­æ–­é”™è¯¯
        if (error.name === 'AbortError' || error.code === 'ERR_CANCELED') {
          logger.debug(`[ChatService] Request aborted: ${requestId}`);
          yield `\n\n[ç”¨æˆ·å·²ä¸­æ–­è¯·æ±‚]`;
          yield `__META__:${JSON.stringify({type:'interrupted'})}`;
          return;
        }
        
        logger.error(`âŒ LLM request failed: ${error.message}`);
        if (error.message.includes('400')) {
          yield `\n\nâŒ è¯·æ±‚å¤±è´¥ï¼ˆä¸Šä¸‹æ–‡å¯èƒ½è¿‡é•¿ï¼‰ã€‚å»ºè®®æ–°å»ºè¯é¢˜é‡è¯•ã€‚`;
        } else {
          yield `\n\nâŒ è¯·æ±‚å¤±è´¥ï¼š${error.message}`;
        }
      }
      
    } catch (error: any) {
      // ğŸ†• æ£€æŸ¥æ˜¯å¦ä¸ºä¸­æ–­é”™è¯¯
      if (error.name === 'AbortError' || error.code === 'ERR_CANCELED') {
        logger.debug(`[ChatService] Request aborted in catch block: ${requestId}`);
        yield `\n\n[ç”¨æˆ·å·²ä¸­æ–­è¯·æ±‚]`;
        yield `__META__:${JSON.stringify({type:'interrupted'})}`;
        return;
      }
      
      logger.error('âŒ Error in ChatService.streamMessage:', error);
      throw error;
    } finally {
      // ğŸ†• æ— è®ºæˆåŠŸæˆ–å¤±è´¥ï¼Œéƒ½æ¸…ç†è¯·æ±‚
      this.cleanupRequest(requestId);
    }
  }
  
  private async requireLLMClient(): Promise<LLMClient> {
    let llmClient = this.llmClient;
    if (!llmClient) {
      // LLMManager æ”¯æŒæ‡’åŠ è½½ï¼Œä» SQLite åŠ è½½é…ç½®
      const { LLMManager } = await import('../core/LLMManager');
      llmClient = new LLMManager() as LLMClient;
      if (!llmClient) {
        throw new Error('LLMClient not available. Please configure LLM providers in admin panel.');
      }
      this.llmClient = llmClient;
    }
    return llmClient;
  }

  /**
   * è§£ææ¶ˆæ¯ä¸­çš„å˜é‡
   * 
   * ä½¿ç”¨SDK VariableEngineç»Ÿä¸€å¤„ç†æ‰€æœ‰å˜é‡å ä½ç¬¦ï¼š
   * - {{Date}}, {{Time}}, {{Today}} - æ—¶é—´å˜é‡ï¼ˆTimeProviderï¼‰
   * - {{TarXXX}}, {{VarXXX}} - ç¯å¢ƒå˜é‡ï¼ˆEnvironmentProviderï¼‰
   * - è‡ªå®šä¹‰å ä½ç¬¦ï¼ˆPlaceholderProviderï¼‰
   * 
   * @param messages - æ¶ˆæ¯æ•°ç»„
   * @returns è§£æåçš„æ¶ˆæ¯æ•°ç»„
   */
  private async resolveVariables(messages: Message[]): Promise<Message[]> {
    logger.debug(`[SDK] Resolving variables in ${messages.length} messages`);
    
    return Promise.all(
      messages.map(async (msg) => {
        if (!msg.content || typeof msg.content !== 'string') {
          return msg;
        }
        
        const originalLength = msg.content.length;
        
        // ğŸ¯ ä½¿ç”¨ProtocolEngineçš„VariableEngineï¼Œä¼ é€’å®Œæ•´çš„VariableContext
        // åŒ…æ‹¬roleã€modelç­‰ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œæ”¯æŒroleè¿‡æ»¤æœºåˆ¶
        const resolvedContent = await this.protocolEngine.variableEngine.resolveAll(
          msg.content,
          {
            role: msg.role || 'system', // ä¼ é€’æ¶ˆæ¯è§’è‰²
            currentMessage: msg.content
          }
        );
        
        // è°ƒè¯•æ—¥å¿—ï¼šæ˜¾ç¤ºè§£æå‰åçš„é•¿åº¦å˜åŒ–
        if (originalLength !== resolvedContent.length) {
          logger.debug(
            `[SDK] Variable resolved (${msg.role}): ${originalLength} â†’ ${resolvedContent.length} chars (+${resolvedContent.length - originalLength})`
          );
        }
        
        return { ...msg, content: resolvedContent };
      })
    );
  }

  private pruneEmptyFields(payload: Record<string, any>): Record<string, any> {
    Object.keys(payload).forEach((key) => {
      const value = payload[key];
      if (
        value === undefined ||
        value === null ||
        (typeof value === 'string' && value.trim().length === 0) ||
        (Array.isArray(value) && value.length === 0)
      ) {
        delete payload[key];
      }
    });
    return payload;
  }
  
  /**
   * ğŸ†• æå–Session Memoryï¼ˆæœ€è¿‘Næ¡æ¶ˆæ¯ï¼‰
   */
  private extractSessionMemory(messages: Message[], limit: number = 50): Message[] {
    // è¿‡æ»¤æ‰systemæ¶ˆæ¯ï¼Œåªä¿ç•™userå’Œassistantæ¶ˆæ¯
    const nonSystemMessages = messages.filter(msg => msg.role !== 'system');
    
    // å–æœ€åNæ¡æ¶ˆæ¯
    const sessionMessages = nonSystemMessages.slice(-limit);
    
    return sessionMessages;
  }

}

