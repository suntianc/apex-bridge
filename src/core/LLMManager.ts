/**
 * LLMManager - LLM ç®¡ç†å™¨ï¼ˆæ–°æ¶æ„ï¼‰
 * 
 * ä½¿ç”¨ä¸¤çº§é…ç½®ç»“æ„ï¼ˆæä¾›å•† + æ¨¡å‹ï¼‰
 * æ”¯æŒå¤šæ¨¡å‹ç±»å‹ï¼ˆNLP, Embedding, Rerank ç­‰ï¼‰
 * é…ç½®ä» SQLite æ•°æ®åº“åŠ è½½ï¼Œæ”¯æŒè¿è¡Œæ—¶çƒ­æ›´æ–°
 */

import { Message, ChatOptions, LLMResponse } from '../types';
import { logger } from '../utils/logger';
import { LLMConfigService } from '../services/LLMConfigService';
import { ModelRegistry } from '../services/ModelRegistry';
import { LLMModelType, LLMModelFull } from '../types/llm-models';
import { buildApiUrl } from '../config/endpoint-mappings';
import { LLMAdapterFactory, ILLMAdapter } from './llm/adapters';

/**
 * LLM ç®¡ç†å™¨ï¼ˆæ–°æ¶æ„ï¼‰
 */
export class LLMManager {
  private adapters: Map<string, ILLMAdapter> = new Map();
  private modelRegistry: ModelRegistry;
  private configService: LLMConfigService;

  constructor() {
    this.configService = LLMConfigService.getInstance();
    this.modelRegistry = ModelRegistry.getInstance();
    
    logger.info('ğŸ¤– Initializing LLM Manager (new architecture)...');
    this.loadProviders();
  }

  /**
   * ä»æ•°æ®åº“åŠ è½½æ‰€æœ‰å¯ç”¨çš„æä¾›å•†
   */
  private loadProviders(): void {
    try {
      const providers = this.configService.listProviders().filter(p => p.enabled);

      if (providers.length === 0) {
        logger.warn('âš ï¸  No enabled LLM providers found');
        return;
      }

      // ä¸ºæ¯ä¸ªæä¾›å•†åˆ›å»ºé€‚é…å™¨
      for (const provider of providers) {
        try {
          // ä½¿ç”¨æä¾›å•†çš„ baseConfig åˆ›å»ºé€‚é…å™¨
          const adapter = LLMAdapterFactory.create(provider.provider, {
            apiKey: provider.baseConfig.apiKey,
            baseURL: provider.baseConfig.baseURL,
            defaultModel: '', // æ¨¡å‹ç”±è°ƒç”¨æ—¶æŒ‡å®š
            timeout: provider.baseConfig.timeout,
            maxRetries: provider.baseConfig.maxRetries
          });
          
          this.adapters.set(provider.provider, adapter);
          logger.info(`âœ… Loaded provider: ${provider.provider} (${provider.name})`);
        } catch (error: any) {
          logger.error(`âŒ Failed to create adapter for ${provider.provider}:`, error.message);
        }
      }

      logger.info(`âœ… Loaded ${this.adapters.size} LLM providers`);
    } catch (error: any) {
      logger.error('âŒ Failed to load providers:', error);
    }
  }

  /**
   * èŠå¤©è¡¥å…¨ï¼ˆè‡ªåŠ¨é€‰æ‹© NLP æ¨¡å‹ï¼‰
   */
  async chat(messages: Message[], options?: ChatOptions): Promise<LLMResponse> {
    try {
      // 1. ç¡®å®šä½¿ç”¨å“ªä¸ªæ¨¡å‹
      let model: LLMModelFull | null = null;

      if (options?.provider && options?.model) {
        // æŒ‡å®šäº†æä¾›å•†å’Œæ¨¡å‹
        model = this.modelRegistry.findModel(options.provider, options.model);
      } else if (options?.provider) {
        // åªæŒ‡å®šäº†æä¾›å•†ï¼Œä½¿ç”¨è¯¥æä¾›å•†çš„é»˜è®¤ NLP æ¨¡å‹
        const provider = this.configService.getProviderByKey(options.provider);
        if (provider) {
          const models = this.configService.listModels({
            providerId: provider.id,
            modelType: LLMModelType.NLP,
            isDefault: true,
            enabled: true
          });
          model = models[0] || null;
        }
      } else {
        // ä½¿ç”¨é»˜è®¤ NLP æ¨¡å‹
        model = this.modelRegistry.getDefaultModel(LLMModelType.NLP);
      }

      if (!model) {
        throw new Error('No NLP model available');
      }

      // 2. è·å–é€‚é…å™¨
      const adapter = this.adapters.get(model.provider);
      if (!adapter) {
        throw new Error(`No adapter found for provider: ${model.provider}`);
      }

      // 3. æ„å»ºå®Œæ•´çš„ API URL
      const apiUrl = model.apiEndpointSuffix 
        ? buildApiUrl(model.providerBaseConfig.baseURL, model.apiEndpointSuffix)
        : model.providerBaseConfig.baseURL;

      // 4. æ›´æ–°é€‚é…å™¨é…ç½®ï¼ˆä½¿ç”¨æ¨¡å‹çš„å®Œæ•´é…ç½®ï¼‰
      const adapterConfig = {
        apiKey: model.providerBaseConfig.apiKey,
        baseURL: apiUrl,
        defaultModel: model.modelKey,
        timeout: model.providerBaseConfig.timeout || 60000,
        maxRetries: model.providerBaseConfig.maxRetries || 3
      };

      // é‡æ–°åˆ›å»ºé€‚é…å™¨ç¡®ä¿ä½¿ç”¨æœ€æ–°é…ç½®
      const freshAdapter = LLMAdapterFactory.create(model.provider, adapterConfig);

      // 5. è°ƒç”¨èŠå¤©
      logger.debug(`ğŸ’¬ Using model: ${model.modelName} (${model.provider}/${model.modelKey})`);
      
      return await freshAdapter.chat(messages, {
        ...options,
        model: model.modelKey
      });

    } catch (error: any) {
      logger.error('âŒ Chat failed:', error);
      throw error;
    }
  }

  /**
   * æµå¼èŠå¤©è¡¥å…¨
   */
  async *streamChat(messages: Message[], options?: ChatOptions, abortSignal?: AbortSignal): AsyncIterableIterator<string> {
    const model = await this.getActiveModel(options);
    
    if (!model) {
      throw new Error('No NLP model available');
    }

    const adapter = await this.getOrCreateAdapter(model);
    
    logger.debug(`ğŸ’¬ Streaming with model: ${model.modelName} (${model.provider}/${model.modelKey})`);
    
    // è°ƒç”¨é€‚é…å™¨çš„ streamChat æ–¹æ³•
    yield* adapter.streamChat(messages, {
      ...options,
      model: model.modelKey
    }, abortSignal);
  }

  /**
   * è·å–æ´»è·ƒçš„æ¨¡å‹ï¼ˆè¾…åŠ©æ–¹æ³•ï¼‰
   */
  private async getActiveModel(options?: ChatOptions): Promise<LLMModelFull | null> {
    if (options?.provider && options?.model) {
      return this.modelRegistry.findModel(options.provider, options.model);
    } else if (options?.provider) {
      const provider = this.configService.getProviderByKey(options.provider);
      if (provider) {
        const models = this.configService.listModels({
          providerId: provider.id,
          modelType: LLMModelType.NLP,
          isDefault: true,
          enabled: true
        });
        return models[0] || null;
      }
    }
    
    return this.modelRegistry.getDefaultModel(LLMModelType.NLP);
  }

  /**
   * è·å–æˆ–åˆ›å»ºé€‚é…å™¨ï¼ˆè¾…åŠ©æ–¹æ³•ï¼‰
   */
  private async getOrCreateAdapter(model: LLMModelFull): Promise<ILLMAdapter> {
    const adapter = this.adapters.get(model.provider);
    if (adapter) {
      return adapter;
    }

    // åŠ¨æ€åˆ›å»ºé€‚é…å™¨
    const apiUrl = model.apiEndpointSuffix 
      ? buildApiUrl(model.providerBaseConfig.baseURL, model.apiEndpointSuffix)
      : model.providerBaseConfig.baseURL;

    const freshAdapter = LLMAdapterFactory.create(model.provider, {
      apiKey: model.providerBaseConfig.apiKey,
      baseURL: apiUrl,
      defaultModel: model.modelKey,
      timeout: model.providerBaseConfig.timeout || 60000,
      maxRetries: model.providerBaseConfig.maxRetries || 3
    });

    this.adapters.set(model.provider, freshAdapter);
    return freshAdapter;
  }

  /**
   * æ–‡æœ¬å‘é‡åŒ–ï¼ˆä½¿ç”¨ Embedding æ¨¡å‹ï¼‰
   */
  async embed(texts: string[], options?: { provider?: string; model?: string }): Promise<number[][]> {
    try {
      // 1. ç¡®å®šä½¿ç”¨å“ªä¸ª Embedding æ¨¡å‹
      let model: LLMModelFull | null = null;

      if (options?.provider && options?.model) {
        model = this.modelRegistry.findModel(options.provider, options.model);
      } else if (options?.provider) {
        const provider = this.configService.getProviderByKey(options.provider);
        if (provider) {
          const models = this.configService.listModels({
            providerId: provider.id,
            modelType: LLMModelType.EMBEDDING,
            isDefault: true,
            enabled: true
          });
          model = models[0] || null;
        }
      } else {
        model = this.modelRegistry.getDefaultModel(LLMModelType.EMBEDDING);
      }

      if (!model) {
        throw new Error('No Embedding model available');
      }

      // 2. æ„å»º API URL
      const apiUrl = model.apiEndpointSuffix 
        ? buildApiUrl(model.providerBaseConfig.baseURL, model.apiEndpointSuffix)
        : model.providerBaseConfig.baseURL;

      // 3. è°ƒç”¨ Embedding API
      logger.debug(`ğŸ”¢ Using embedding model: ${model.modelName} (${model.provider}/${model.modelKey})`);
      
      // TODO: å®ç°å®é™…çš„ embedding è°ƒç”¨
      // è¿™é‡Œéœ€è¦æ ¹æ®ä¸åŒæä¾›å•†çš„ API æ ¼å¼è°ƒç”¨
      
      throw new Error('Embedding not yet implemented');
    } catch (error: any) {
      logger.error('âŒ Embed failed:', error);
      throw error;
    }
  }

  /**
   * åˆ·æ–°é…ç½®ï¼ˆé‡æ–°åŠ è½½æä¾›å•†ï¼‰
   */
  public refresh(): void {
    logger.info('ğŸ”„ Refreshing LLM Manager...');
    this.adapters.clear();
    this.loadProviders();
    this.modelRegistry.forceRefresh();
  }

  /**
   * è·å–å¯ç”¨çš„æä¾›å•†åˆ—è¡¨
   */
  public getAvailableProviders(): string[] {
    return Array.from(this.adapters.keys());
  }

  /**
   * æ£€æŸ¥æä¾›å•†æ˜¯å¦å¯ç”¨
   */
  public hasProvider(provider: string): boolean {
    return this.adapters.has(provider);
  }

  /**
   * æ›´æ–°æä¾›å•†é…ç½®ï¼ˆæ•°æ®åº“ + å†…å­˜ï¼‰
   */
  async updateProvider(id: number, input: any): Promise<void> {
    // æ›´æ–°æ•°æ®åº“
    this.configService.updateProvider(id, input);
    
    // åˆ·æ–°å†…å­˜
    this.refresh();
  }

  /**
   * è·å–æ‰€æœ‰æ¨¡å‹ï¼ˆç”¨äº APIï¼‰
   */
  public getAllModels(): Array<{ id: string; provider: string; model: string; type: string }> {
    const models = this.modelRegistry.getAllModels();
    return models.map(m => ({
      id: `${m.provider}/${m.modelKey}`,
      provider: m.provider,
      model: m.modelKey,
      type: m.modelType
    }));
  }
}
