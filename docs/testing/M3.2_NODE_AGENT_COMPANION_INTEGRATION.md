# M3.2 节点代理 Hub 实机联调报告

- **测试日期**：2025-11-09
- **参与模块**：NodeManager（Hub）、Companion Node Agent、LLM Proxy、QuotaManager
- **测试目标**：验证 Companion 节点通过 WebSocket 与 Hub 实际协同，覆盖流式回复、配额限流降级以及任务闭环。

## 1. 环境准备

1. 根目录设置临时运行环境：
   ```bash
   set APEX_BRIDGE_ROOT_DIR=%TEMP%\apex-companion-int
   set APEX_BRIDGE_CONFIG_DIR=%APEX_BRIDGE_ROOT_DIR%\config
   set APEX_BRIDGE_DATA_DIR=%APEX_BRIDGE_ROOT_DIR%\data
   ```
2. 安装依赖并进入节点代理目录：
   ```bash
   cd packages/node-agent
   npm install
   ```

## 2. 执行命令

```bash
npm run test -- hub-companion.integration.test.ts
```

该命令会：
- 启动真实 `NodeManager` + 自定义 `NodeAwareDistributedServerChannel` WebSocket 服务。
- 启动 Companion Node Agent 运行时（心跳周期 200ms，默认流式 LLM）。
- 触发两类任务：
  1. **流式对话**：`messages=["请用中文问候我"]`，预期返回流式分片与最终聚合回复。
  2. **限流降级**：重复发起第二次流式任务，QuotaManager（每分钟 1 次）立即拒绝，Companion 使用 `metadata.fallbackReply` 输出降级文案。

## 3. 观察指标

| 场景 | 期望 | 结果 |
|------|------|------|
| 流式对话任务 | `partialOutputs` ≥ 2，最终回复 `你好，世界` | ✅ | 
| 限流降级 | 触发 `llm_proxy_rate_limited` 事件，Companion 返回 `degraded: true` 与备用文案 | ✅ |
| 事件总线 | `llm_proxy_stream_chunk`、`task_completed`、`llm_proxy_rate_limited` 均被记录 | ✅ |
| Quota 状态 | 第二次请求立即被 `requests_per_minute` 拒绝，message `Too many LLM requests per minute` | ✅ |

## 4. 结论

- Companion 节点在真实 Hub 下完成注册 → 心跳 → 任务执行 → 结果回传闭环。
- 流式通路能输出分片、聚合结果及统计信息；限流场景下 fallback 正常触发。
- 新增测试文件 `tests/integration/hub-companion.integration.test.ts` 已纳入 `npm run test` 全量流程。

> 若需要人工演示，可执行上述命令并在 `node-agent` 目录查看日志输出；心跳与事件推送已在测试中验证。
