## Context

Apex Bridge v2.0需要实现情感引擎，让AI能够识别用户情绪并做出共情响应。这是MVP核心功能之一，依赖已完成的PersonalityEngine。

## Goals / Non-Goals

### Goals
- 实现基于LLM的快速情感识别
- 支持6种基础情感类型
- 实现人格化的共情响应
- 确保性能（延迟 < 100ms）
- 支持情感记录（可选，为后续记忆增强打基础）

### Non-Goals
- MVP阶段不实现情感学习（后续M2.1记忆增强时实现）
- MVP阶段不实现复杂情感模型（仅支持6种基础情感）
- MVP阶段不实现多模态情感识别（仅文本）

## Decisions

### 决策1: 情感识别策略
**选择**: 基于LLM的快速分析（非训练模型）
**理由**: 
- 无需训练模型，快速实现
- LLM理解能力强，准确率高
- 可复用现有LLMClient
**备选方案**: 使用预训练情感分类模型（需要额外依赖，复杂度高）

### 决策2: 情感识别时机
**选择**: 在LLM调用前识别，将情感信息注入System Prompt
**理由**: 
- 让LLM在生成回复时考虑用户情绪
- 自然、无缝的集成方式
- 不增加额外API调用（复用对话流程）
**备选方案**: 独立的情感识别API（增加延迟，不推荐）

### 决策3: 情感响应实现方式
**选择**: 响应模板库 + 人格化调整
**理由**: 
- 快速、可控、可预测
- 不同人格有不同响应风格
- 易于维护和扩展
**备选方案**: 完全由LLM生成（不可控，风格不一致）

### 决策4: 性能优化策略
**选择**: LLM快速识别 + 缓存机制 + 可选快速模式
**理由**: 
- LLM识别准确但可能慢，需要优化提示词
- 缓存相同消息的情感识别结果
- 快速模式（关键词匹配）作为备用
**实施**: 
- 优化提示词（简短、结构化）
- 缓存策略（相同消息内容缓存结果）
- 快速模式（简单关键词匹配，如"开心"→happy）

### 决策5: 情感记录策略
**选择**: MVP阶段实现接口，但不强制存储
**理由**: 
- 为后续M2.1记忆增强预留接口
- MVP阶段可选择性记录（配置控制）
- 不影响核心功能

### 决策6: 情感类型定义
**选择**: 6种基础情感（happy/sad/angry/excited/neutral/anxious）
**理由**: 
- 覆盖常见情绪
- 足够但不过于复杂
- 后续可扩展

## Risks / Trade-offs

### 风险1: LLM情感识别延迟
**缓解**: 
- 优化提示词，缩短token
- 使用快速模式作为备用
- 缓存机制减少重复识别

### 风险2: 情感识别准确率
**缓解**: 
- 使用结构化提示词（JSON输出）
- 提供置信度评分
- 允许手动校正

### 风险3: 情感响应模板维护
**缓解**: 
- 使用JSON配置文件，易于维护
- 提供模板示例和文档
- 支持运行时刷新

## Migration Plan

### 向后兼容
- 完全向后兼容，不影响现有功能
- 情感识别失败时fallback到正常回复
- 可通过配置禁用情感识别

### 扩展路径
- MVP阶段：基础情感识别和响应
- 后续：情感学习（M2.1）、情感历史（M2.4时间线）

## Open Questions

无（所有设计决策已确定）

