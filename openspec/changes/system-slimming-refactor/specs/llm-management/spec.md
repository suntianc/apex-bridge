# LLMç®¡ç†å™¨é‡æ„è§„èŒƒ

## å˜æ›´ç±»å‹
`MODIFIED`

## å˜æ›´èŒƒå›´
- æ¨¡å—ï¼š`core/LLMClient.ts` â†’ `core/LLMManager.ts`ï¼ˆé‡å‘½å+å¢å¼ºï¼‰
- å½±å“ï¼š`services/ChatService.ts`ã€`api/controllers/chat-controller.ts`
- é…ç½®ï¼š`config/*.yml`ï¼ˆLLM é…ç½®é¡¹ä¿æŒä¸å˜ï¼‰

## ç›®æ ‡
å°† LLM å®¢æˆ·ç«¯ä»ç®€å•çš„é€‚é…å™¨å‡çº§ä¸ºå…¨åŠŸèƒ½çš„ç®¡ç†å™¨ï¼Œæä¾›å¥åº·æ£€æŸ¥ã€è´Ÿè½½å‡è¡¡å’Œæ•…éšœè½¬ç§»èƒ½åŠ›ï¼Œæå‡ç³»ç»Ÿç¨³å®šæ€§å’Œå¯ç”¨æ€§ã€‚

## MODIFIED Requirements

### èƒ½åŠ› 1ï¼šå¥åº·æ£€æŸ¥

#### åœºæ™¯ï¼šæ£€æµ‹å¤šä¸ª LLM æä¾›å•†çš„å¯ç”¨æ€§

**Given** ç³»ç»Ÿé…ç½®äº†å¤šä¸ª LLM æä¾›å•†ï¼ˆOpenAIã€DeepSeekã€Claudeã€Ollama ç­‰ï¼‰
**When** è°ƒç”¨ `llmManager.healthCheck()`
**Then** ç³»ç»Ÿåº”è¿”å›æ‰€æœ‰æä¾›å•†çš„å¥åº·çŠ¶æ€ï¼ŒåŒ…æ‹¬ï¼š
- provider åç§°
- statusï¼ˆhealthy/degraded/downï¼‰
- latencyï¼ˆå“åº”å»¶è¿Ÿï¼‰
- lastErrorï¼ˆå¦‚æœæœ‰é”™è¯¯ï¼‰

**ç¤ºä¾‹ï¼š**
```typescript
const health = await llmManager.healthCheck();
// è¿”å›:
// [
//   { provider: 'openai', status: 'healthy', latency: 120 },
//   { provider: 'deepseek', status: 'down', latency: 5000, lastError: 'Timeout' }
// ]
```

**Given** æŒ‡å®šç‰¹å®šæä¾›å•†
**When** è°ƒç”¨ `llmManager.healthCheck('openai')`
**Then** åªè¿”å›è¯¥æä¾›å•†çš„å¥åº·çŠ¶æ€

### èƒ½åŠ› 2ï¼šæ™ºèƒ½æä¾›å•†é€‰æ‹©

#### åœºæ™¯ï¼šæ ¹æ®æ¨¡å‹åç§°è‡ªåŠ¨é€‰æ‹©æä¾›å•†

**Given** ç”¨æˆ·è¯·æ±‚ä½¿ç”¨æ¨¡å‹ "gpt-4o-mini"
**When** è°ƒç”¨ `llmManager.switchProvider('gpt-4o-mini')`
**Then** ç³»ç»Ÿåº”æ ¹æ®æ¨¡å‹å‰ç¼€è‡ªåŠ¨é€‰æ‹©æä¾›å•†ï¼š
- `gpt-*` â†’ 'openai'
- `deepseek-*` â†’ 'deepseek'
- `claude-*` â†’ 'claude'
- `llama*`, `qwen*`, `mistral*` â†’ 'ollama'

**Given** æ¨¡å‹æ— æ³•åŒ¹é…ä»»ä½•è§„åˆ™
**When** è°ƒç”¨ `llmManager.switchProvider('unknown-model')`
**Then** è¿”å›é…ç½®çš„é»˜è®¤æä¾›å•†

### èƒ½åŠ› 3ï¼šè´Ÿè½½å‡è¡¡

#### åœºæ™¯ï¼šåœ¨å¤šä¸ªå¥åº·æä¾›å•†é—´åˆ†å‘è¯·æ±‚

**Given** æä¾›å•†åˆ—è¡¨ ['openai', 'deepseek', 'claude']
**And** æ‰€æœ‰æä¾›å•†éƒ½å¤„äº healthy çŠ¶æ€
**When** å¤šæ¬¡è°ƒç”¨ `llmManager.loadBalance(['openai', 'deepseek'], messages, options)`
**Then** è¯·æ±‚åº”å‡åŒ€åˆ†å‘åˆ°å„ä¸ªæä¾›å•†ï¼ˆè½®è¯¢æˆ–éšæœºç®—æ³•ï¼‰

**Given** æŸä¸ªæä¾›å•†å¤„äº down çŠ¶æ€
**When** è°ƒç”¨è´Ÿè½½å‡è¡¡
**Then** è‡ªåŠ¨è·³è¿‡ down çš„æä¾›å•†ï¼Œåªä½¿ç”¨ healthy çš„æä¾›å•†

### èƒ½åŠ› 4ï¼šæ•…éšœè½¬ç§»é“¾

#### åœºæ™¯ï¼šæŒ‰ä¼˜å…ˆçº§å°è¯•å¤šä¸ªæä¾›å•†

**Given** æä¾›å•†ä¼˜å…ˆçº§åˆ—è¡¨ ['openai', 'deepseek', 'claude']
**When** è°ƒç”¨ `llmManager.fallbackChain(['openai', 'deepseek', 'claude'], messages, options)`
**Then** ç³»ç»Ÿåº”æŒ‰é¡ºåºå°è¯•ï¼š
1. é¦–å…ˆå°è¯• 'openai'
2. å¦‚æœå¤±è´¥ï¼Œå°è¯• 'deepseek'
3. å¦‚æœå¤±è´¥ï¼Œå°è¯• 'claude'
4. å¦‚æœå…¨éƒ¨å¤±è´¥ï¼ŒæŠ›å‡ºé”™è¯¯

**ç¤ºä¾‹ï¼š**
```typescript
try {
  const response = await llmManager.fallbackChain(
    ['openai', 'deepseek', 'claude'],
    messages,
    { model: 'gpt-4o-mini' }
  );
  // ä½¿ç”¨ç¬¬ä¸€ä¸ªæˆåŠŸçš„å“åº”
} catch (error) {
  // æ‰€æœ‰æä¾›å•†éƒ½å¤±è´¥
}
```

### èƒ½åŠ› 5ï¼šæ€§èƒ½æŒ‡æ ‡ç›‘æ§

#### åœºæ™¯ï¼šè·å–æä¾›å•†ä½¿ç”¨ç»Ÿè®¡

**Given** ç³»ç»Ÿè¿è¡Œä¸€æ®µæ—¶é—´ï¼Œæœ‰å¤šä¸ª LLM è¯·æ±‚
**When** è°ƒç”¨ `llmManager.getProviderMetrics()`
**Then** è¿”å›æ¯ä¸ªæä¾›å•†çš„ç»Ÿè®¡ä¿¡æ¯ï¼š
- provider åç§°
- requestsï¼ˆè¯·æ±‚æ¬¡æ•°ï¼‰
- errorsï¼ˆé”™è¯¯æ¬¡æ•°ï¼‰
- avgLatencyï¼ˆå¹³å‡å»¶è¿Ÿï¼‰
- costPer1Kï¼ˆä¼°ç®—çš„æ¯åƒæ¬¡æˆæœ¬ï¼‰

## å…¼å®¹æ€§è¦æ±‚

### åœºæ™¯ï¼šä¿æŒå‘åå…¼å®¹

**Given** ç°æœ‰ä»£ç ä½¿ç”¨ `llmClient.chat()` å’Œ `llmClient.streamChat()`
**When** å‡çº§åˆ° LLMManager
**Then** åŸæœ‰æ¥å£åº”ä¿æŒä¸å˜ï¼Œæ— éœ€ä¿®æ”¹è°ƒç”¨ä»£ç 

### ADDED Requirements

#### åœºæ™¯ï¼šå®šæœŸå¥åº·ç›‘æ§

**Given** ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²
**When** é…ç½®å®šæ—¶ä»»åŠ¡æ¯ 30 ç§’æ‰§è¡Œå¥åº·æ£€æŸ¥
**Then** ç³»ç»Ÿåº”è®°å½•å¥åº·çŠ¶æ€åˆ°æ—¥å¿—
**And** å¯ç”¨äºç›‘æ§é¢æ¿å±•ç¤º

**ç¤ºä¾‹ä»£ç ï¼š**
```typescript
setInterval(async () => {
  const health = await llmManager.healthCheck();
  logger.info('ğŸ¥ LLM Health Check:', health);
}, 30000);
```

## æŠ€æœ¯æ–¹æ¡ˆ

### æ–‡ä»¶å˜æ›´

```
src/core/
â”œâ”€â”€ LLMClient.ts â†’ LLMManager.tsï¼ˆé‡å‘½å + å¢å¼ºï¼‰
â””â”€â”€ types/llm.tsï¼ˆå¯èƒ½éœ€è¦æ–°å¢ç±»å‹å®šä¹‰ï¼‰
```

### æ¥å£å®šä¹‰

```typescript
// src/core/types/llm.ts

export interface ProviderHealth {
  provider: string;
  status: 'healthy' | 'degraded' | 'down';
  latency: number;
  lastError?: string;
}

export interface ProviderMetrics {
  provider: string;
  requests: number;
  errors: number;
  avgLatency: number;
  costPer1K: number;
}

// src/core/LLMManager.ts

export class LLMManager {
  // åŸæœ‰æ¥å£ï¼ˆä¿æŒä¸å˜ï¼‰
  async chat(messages: Message[], options: ChatOptions): Promise<LLMResponse>;
  async *streamChat(messages: Message[], options: ChatOptions, signal?: AbortSignal): AsyncIterableIterator<string>;
  async getAllModels(): Promise<Array<{id: string, provider: string}>>;

  // æ–°å¢æ¥å£
  async healthCheck(provider?: string): Promise<ProviderHealth[]>;
  async switchProvider(model: string): Promise<string>;
  async loadBalance(providers: string[], messages: Message[], options: ChatOptions): Promise<LLMResponse>;
  async fallbackChain(providers: string[], messages: Message[], options: ChatOptions): Promise<LLMResponse>;
  async getProviderMetrics(): Promise<ProviderMetrics[]>;
}
```

### å®ç°ç»†èŠ‚

1. **å¥åº·æ£€æŸ¥**ï¼šè°ƒç”¨æ¯ä¸ªæä¾›å•†çš„ `getModels()` ç«¯ç‚¹ï¼Œæµ‹é‡å“åº”æ—¶é—´
2. **è´Ÿè½½å‡è¡¡**ï¼šä½¿ç”¨è½®è¯¢æˆ–éšæœºç®—æ³•é€‰æ‹© healthy æä¾›å•†
3. **æ•…éšœè½¬ç§»**ï¼šä½¿ç”¨ for+try/catch å¾ªç¯å®ç°é¡ºåºå°è¯•
4. **æ€§èƒ½æŒ‡æ ‡**ï¼šåœ¨æ¯æ¬¡è¯·æ±‚æ—¶è®°å½•ç»Ÿè®¡ä¿¡æ¯åˆ°å†…å­˜ï¼ˆæˆ–å¯é€‰çš„å¤–éƒ¨å­˜å‚¨ï¼‰

### é…ç½®ç¤ºä¾‹

```yaml
llm:
  defaultProvider: 'openai'  # é»˜è®¤æä¾›å•†
  healthCheck:
    enabled: true
    interval: 30000  # å¥åº·æ£€æŸ¥é—´éš”ï¼ˆæ¯«ç§’ï¼‰
  loadBalance:
    enabled: false
    strategy: 'round-robin'  # è½®è¯¢æˆ– random
  fallback:
    enabled: true
    chain: ['openai', 'deepseek', 'claude']  # æ•…éšœè½¬ç§»é¡ºåº

  # æä¾›å•†é…ç½®ï¼ˆä¿æŒä¸å˜ï¼‰
  openai:
    baseURL: 'https://api.openai.com/v1'
    apiKey: '${OPENAI_API_KEY}'
    defaultModel: 'gpt-4o-mini'

  deepseek:
    baseURL: 'https://api.deepseek.com/v1'
    apiKey: '${DEEPSEEK_API_KEY}'
    defaultModel: 'deepseek-chat'
```

## æµ‹è¯•ç­–ç•¥

### å•å…ƒæµ‹è¯•

1. **å¥åº·æ£€æŸ¥æµ‹è¯•**
   - æµ‹è¯•å•ä¸ªæä¾›å•†å¥åº·æ£€æŸ¥
   - æµ‹è¯•å¤šä¸ªæä¾›å•†å¥åº·æ£€æŸ¥
   - æµ‹è¯•è¶…æ—¶å’Œé”™è¯¯å¤„ç†

2. **è´Ÿè½½å‡è¡¡æµ‹è¯•**
   - æµ‹è¯•è¯·æ±‚åˆ†å‘å‡åŒ€æ€§
   - æµ‹è¯•è·³è¿‡ down æä¾›å•†
   - æµ‹è¯•æ— å¯ç”¨æä¾›å•†é”™è¯¯

3. **æ•…éšœè½¬ç§»æµ‹è¯•**
   - æµ‹è¯•é¡ºåºå°è¯•æœºåˆ¶
   - æµ‹è¯•é¦–æ¬¡æˆåŠŸåœæ­¢
   - æµ‹è¯•å…¨éƒ¨å¤±è´¥é”™è¯¯

4. **æŒ‡æ ‡æµ‹è¯•**
   - æµ‹è¯•è¯·æ±‚è®¡æ•°
   - æµ‹è¯•é”™è¯¯è®¡æ•°
   - æµ‹è¯•å»¶è¿Ÿè®¡ç®—

### é›†æˆæµ‹è¯•

1. **å®Œæ•´è¯·æ±‚æµç¨‹**
   - é…ç½®å¤šä¸ªæä¾›å•†
   - å‘é€å¯¹è¯è¯·æ±‚
   - éªŒè¯å¥åº·æ£€æŸ¥ã€è´Ÿè½½å‡è¡¡ã€æ•…éšœè½¬ç§»ååŒå·¥ä½œ

2. **ç”Ÿäº§åœºæ™¯æ¨¡æ‹Ÿ**
   - æ¨¡æ‹Ÿæä¾›å•†æ•…éšœ
   - éªŒè¯è‡ªåŠ¨åˆ‡æ¢åˆ°å¤‡ç”¨æä¾›å•†
   - éªŒè¯æœåŠ¡ä¸ä¸­æ–­

## æ€§èƒ½å½±å“

### æ­£é¢å½±å“

1. **æå‡å¯ç”¨æ€§**ï¼šæ•…éšœè½¬ç§»å‡å°‘æœåŠ¡ä¸­æ–­
2. **è´Ÿè½½åˆ†å‘**ï¼šé˜²æ­¢å•ä¸ªæä¾›å•†è¿‡è½½
3. **æˆæœ¬æ§åˆ¶**ï¼šå¯é€‰æ‹©æˆæœ¬æ›´ä½çš„æä¾›å•†

### æ½œåœ¨è´Ÿé¢å½±å“

1. **å¥åº·æ£€æŸ¥å¼€é”€**ï¼šå®šæœŸå¥åº·æ£€æŸ¥å¢åŠ å°‘é‡ç½‘ç»œè¯·æ±‚
   - ç¼“è§£ï¼šå¯é…ç½®æ£€æŸ¥é—´éš”ï¼Œæˆ–æŒ‰éœ€æ£€æŸ¥

2. **æ•…éšœè½¬ç§»å»¶è¿Ÿ**ï¼šé¦–æ¬¡è¯·æ±‚å¤±è´¥åæ‰å°è¯•å¤‡ç”¨
   - ç¼“è§£ï¼šå¥åº·æ£€æŸ¥æå‰å‘ç°æ•…éšœï¼Œè·¯ç”±åˆ°å¥åº·èŠ‚ç‚¹

### æ€§èƒ½ç›®æ ‡

- å¥åº·æ£€æŸ¥å“åº”æ—¶é—´ï¼š`< 200ms`
- æ•…éšœè½¬ç§»å»¶è¿Ÿï¼š`< 1s`ï¼ˆå½“ä¸»æä¾›å•†æ•…éšœæ—¶ï¼‰
- è´Ÿè½½å‡è¡¡é¢å¤–å¼€é”€ï¼š`< 10ms`

## ç›¸å…³ä»»åŠ¡

- [ ] é‡å‘½å LLMClient.ts â†’ LLMManager.ts
- [ ] æ–°å¢ ProviderHealth å’Œ ProviderMetrics æ¥å£
- [ ] å®ç° healthCheck() æ–¹æ³•
- [ ] å®ç° switchProvider() æ–¹æ³•
- [ ] å®ç° loadBalance() æ–¹æ³•
- [ ] å®ç° fallbackChain() æ–¹æ³•
- [ ] å®ç° getProviderMetrics() æ–¹æ³•
- [ ] æ›´æ–° ChatService ä»¥ä½¿ç”¨ LLMManagerï¼ˆå¦‚æœä¸å…¼å®¹ï¼‰
- [ ] æ·»åŠ  LLM ç®¡ç†é…ç½®åˆ°é…ç½®æ–‡ä»¶
- [ ] ç¼–å†™å•å…ƒæµ‹è¯•
- [ ] ç¼–å†™é›†æˆæµ‹è¯•
- [ ] æ›´æ–° API æ–‡æ¡£
- [ ] æ€§èƒ½åŸºå‡†æµ‹è¯•
