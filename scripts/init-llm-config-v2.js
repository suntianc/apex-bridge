#!/usr/bin/env node
/**
 * åˆå§‹åŒ– LLM é…ç½® v2 æ¶æ„
 * 
 * ä½¿ç”¨æ–¹æ³•:
 *   node scripts/init-llm-config-v2.js
 */

const Database = require('better-sqlite3');
const path = require('path');
const fs = require('fs');

const dataDir = path.join(__dirname, '..', 'data');
if (!fs.existsSync(dataDir)) {
  fs.mkdirSync(dataDir, { recursive: true });
}

const dbPath = path.join(dataDir, 'llm_providers.db');
const db = new Database(dbPath);

console.log('');
console.log('='.repeat(70));
console.log('  ApexBridge LLM é…ç½®åˆå§‹åŒ– v2.0');
console.log('='.repeat(70));
console.log('');
console.log('ğŸ“¦ æ•°æ®åº“è·¯å¾„:', dbPath);
console.log('');

// åˆå§‹åŒ–è¡¨ç»“æ„ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
db.exec(`
  CREATE TABLE IF NOT EXISTS llm_providers (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    provider TEXT NOT NULL UNIQUE,
    name TEXT NOT NULL,
    description TEXT,
    base_config TEXT NOT NULL,
    enabled INTEGER DEFAULT 1,
    created_at INTEGER NOT NULL,
    updated_at INTEGER NOT NULL,
    CHECK(enabled IN (0, 1))
  );

  CREATE TABLE IF NOT EXISTS llm_models (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    provider_id INTEGER NOT NULL,
    model_key TEXT NOT NULL,
    model_name TEXT NOT NULL,
    model_type TEXT NOT NULL,
    model_config TEXT NOT NULL,
    api_endpoint_suffix TEXT,
    enabled INTEGER DEFAULT 1,
    is_default INTEGER DEFAULT 0,
    display_order INTEGER DEFAULT 0,
    created_at INTEGER NOT NULL,
    updated_at INTEGER NOT NULL,
    FOREIGN KEY (provider_id) REFERENCES llm_providers(id) ON DELETE CASCADE,
    UNIQUE(provider_id, model_key),
    CHECK(enabled IN (0, 1)),
    CHECK(is_default IN (0, 1)),
    CHECK(model_type IN ('nlp', 'embedding', 'rerank', 'image', 'multimodal', 'audio', 'other'))
  );
  
  CREATE INDEX IF NOT EXISTS idx_provider ON llm_providers(provider);
  CREATE INDEX IF NOT EXISTS idx_provider_enabled ON llm_providers(enabled);
  CREATE INDEX IF NOT EXISTS idx_model_provider ON llm_models(provider_id);
  CREATE INDEX IF NOT EXISTS idx_model_type ON llm_models(model_type);
  CREATE INDEX IF NOT EXISTS idx_model_enabled ON llm_models(enabled);
  CREATE INDEX IF NOT EXISTS idx_model_default ON llm_models(is_default);
  CREATE INDEX IF NOT EXISTS idx_model_key ON llm_models(model_key);
  CREATE INDEX IF NOT EXISTS idx_model_type_default ON llm_models(model_type, is_default);
`);

console.log('âœ… æ•°æ®åº“è¡¨ç»“æ„å·²ç¡®è®¤\n');

// æä¾›å•†é…ç½®
const providers = [
  {
    provider: 'deepseek',
    name: 'DeepSeek',
    description: 'DeepSeek AI - é«˜æ€§ä»·æ¯”èŠå¤©å’Œä»£ç æ¨¡å‹',
    baseConfig: {
      apiKey: process.env.DEEPSEEK_API_KEY || 'sk-your-deepseek-api-key',
      baseURL: 'https://api.deepseek.com',
      timeout: 60000,
      maxRetries: 3
    },
    enabled: true,
    models: [
      {
        modelKey: 'deepseek-chat',
        modelName: 'DeepSeek Chat',
        modelType: 'nlp',
        modelConfig: { contextWindow: 32000, maxTokens: 4096 },
        apiEndpointSuffix: '/chat/completions',
        enabled: true,
        isDefault: true
      },
      {
        modelKey: 'deepseek-coder',
        modelName: 'DeepSeek Coder',
        modelType: 'nlp',
        modelConfig: { contextWindow: 16000, maxTokens: 4096 },
        apiEndpointSuffix: '/chat/completions',
        enabled: true,
        isDefault: false
      }
    ]
  },
  {
    provider: 'openai',
    name: 'OpenAI',
    description: 'OpenAI GPT ç³»åˆ—æ¨¡å‹',
    baseConfig: {
      apiKey: process.env.OPENAI_API_KEY || 'sk-your-openai-api-key',
      baseURL: 'https://api.openai.com/v1',
      timeout: 60000,
      maxRetries: 3
    },
    enabled: false,
    models: [
      {
        modelKey: 'gpt-4',
        modelName: 'GPT-4',
        modelType: 'nlp',
        modelConfig: { contextWindow: 128000, maxTokens: 4096 },
        apiEndpointSuffix: '/chat/completions',
        enabled: true,
        isDefault: true
      },
      {
        modelKey: 'gpt-3.5-turbo',
        modelName: 'GPT-3.5 Turbo',
        modelType: 'nlp',
        modelConfig: { contextWindow: 16384, maxTokens: 4096 },
        apiEndpointSuffix: '/chat/completions',
        enabled: true,
        isDefault: false
      },
      {
        modelKey: 'text-embedding-ada-002',
        modelName: 'Ada Embeddings v2',
        modelType: 'embedding',
        modelConfig: { dimensions: 1536 },
        apiEndpointSuffix: '/embeddings',
        enabled: true,
        isDefault: true
      },
      {
        modelKey: 'gpt-4o',
        modelName: 'GPT-4o (å¤šæ¨¡æ€)',
        modelType: 'multimodal',
        modelConfig: { contextWindow: 128000, maxTokens: 4096 },
        apiEndpointSuffix: '/chat/completions',
        enabled: false,
        isDefault: false
      }
    ]
  },
  {
    provider: 'qwen',
    name: 'Qwen (é€šä¹‰åƒé—®)',
    description: 'é˜¿é‡Œäº‘é€šä¹‰åƒé—® VL æ¨¡å‹',
    baseConfig: {
      apiKey: process.env.QWEN_API_KEY || 'sk-your-qwen-api-key',
      baseURL: 'https://dashscope.aliyuncs.com/compatible-mode/v1',
      timeout: 60000,
      maxRetries: 3
    },
    enabled: false,
    models: [
      {
        modelKey: 'qwen2-vl-72b-instruct',
        modelName: 'Qwen2-VL 72B',
        modelType: 'multimodal',
        modelConfig: { contextWindow: 128000, maxTokens: 4096 },
        apiEndpointSuffix: '/chat/completions',
        enabled: false,
        isDefault: true
      },
      {
        modelKey: 'qwen-turbo',
        modelName: 'Qwen Turbo',
        modelType: 'nlp',
        modelConfig: { contextWindow: 8000, maxTokens: 2000 },
        apiEndpointSuffix: '/chat/completions',
        enabled: false,
        isDefault: false
      }
    ]
  }
];

console.log('ğŸ“ æ·»åŠ æä¾›å•†å’Œæ¨¡å‹é…ç½®...\n');

const now = Date.now();
let providerCount = 0;
let modelCount = 0;

const providerStmt = db.prepare(`
  INSERT OR REPLACE INTO llm_providers (provider, name, description, base_config, enabled, created_at, updated_at)
  VALUES (?, ?, ?, ?, ?, ?, ?)
`);

const modelStmt = db.prepare(`
  INSERT OR REPLACE INTO llm_models (
    provider_id, model_key, model_name, model_type, model_config,
    api_endpoint_suffix, enabled, is_default, display_order, created_at, updated_at
  ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
`);

providers.forEach(p => {
  try {
    // æ’å…¥æä¾›å•†
    const result = providerStmt.run(
      p.provider,
      p.name,
      p.description,
      JSON.stringify(p.baseConfig),
      p.enabled ? 1 : 0,
      now,
      now
    );
    
    const providerId = result.lastInsertRowid || db.prepare('SELECT id FROM llm_providers WHERE provider = ?').get(p.provider).id;
    providerCount++;
    
    const status = p.enabled ? 'âœ…' : 'âšª';
    console.log(`${status} ${p.name} (${p.provider})`);
    
    // æ’å…¥æ¨¡å‹
    p.models.forEach((m, idx) => {
      modelStmt.run(
        providerId,
        m.modelKey,
        m.modelName,
        m.modelType,
        JSON.stringify(m.modelConfig),
        m.apiEndpointSuffix,
        m.enabled ? 1 : 0,
        m.isDefault ? 1 : 0,
        idx,
        now,
        now
      );
      
      const modelStatus = m.enabled ? 'âœ…' : 'âšª';
      const defaultMark = m.isDefault ? ' ğŸŒŸ' : '';
      console.log(`    ${modelStatus} ${m.modelName} [${m.modelType}]${defaultMark}`);
      modelCount++;
    });
    
    console.log('');
  } catch (error) {
    console.error(`âŒ æ·»åŠ  ${p.name} å¤±è´¥:`, error.message);
  }
});

console.log('='.repeat(70));
console.log(`âœ… æˆåŠŸæ·»åŠ  ${providerCount} ä¸ªæä¾›å•†, ${modelCount} ä¸ªæ¨¡å‹`);
console.log('='.repeat(70));
console.log('');

// æ˜¾ç¤ºç»Ÿè®¡
const stats = db.prepare(`
  SELECT 
    p.name as provider_name,
    COUNT(m.id) as model_count,
    SUM(CASE WHEN m.enabled = 1 THEN 1 ELSE 0 END) as enabled_models
  FROM llm_providers p
  LEFT JOIN llm_models m ON p.id = m.provider_id
  GROUP BY p.id, p.name
`).all();

console.log('ğŸ“Š é…ç½®ç»Ÿè®¡:');
stats.forEach(s => {
  console.log(`  ${s.provider_name}: ${s.model_count} ä¸ªæ¨¡å‹ (${s.enabled_models} ä¸ªå·²å¯ç”¨)`);
});
console.log('');

db.close();

console.log('ğŸ“‹ ä¸‹ä¸€æ­¥æ“ä½œ:');
console.log('  1. æŸ¥çœ‹é…ç½®: node scripts/view-llm-config-v2.js');
console.log('  2. å¯åŠ¨æœåŠ¡: npm run dev');
console.log('  3. æµ‹è¯• API: curl http://localhost:8088/api/llm/providers');
console.log('');

